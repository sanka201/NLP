{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sanka/anaconda3/envs/tf-env-ultimate/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/sanka/anaconda3/envs/tf-env-ultimate/lib/python3.10/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "2024-07-02 15:52:27.786925: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-02 15:52:28.966323: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/sanka/anaconda3/envs/tf-env-ultimate/lib/python3.10/site-packages/threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import re, time\n",
    "import pandas as pd\n",
    "from haystack.components.builders import PromptBuilder\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "from haystack import Pipeline, Document\n",
    "\n",
    "import os\n",
    "from getpass import getpass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_log_file(file_path)-> pd:\n",
    "    pattern = r'(?P<timestamp>\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2},\\d{3}) \\((?P<agent>[\\w.-]+[^)]+)\\) (?P<debug>[A-Za-z_\\.]+) (?P<level>[A-Z]+): (?P<message>.*)'\n",
    "    #pattern = r'^(?P<timestamp>[\\d-]+\\s[\\d:,]+)\\s\\((?P<module>[\\w.-]+)\\s(?P<process_id>\\d+)\\s\\[(?P<thread_id>\\d+)\\]\\)\\s(?P<source>[\\w.]+)\\s(?P<log_level>\\w+):\\s(?P<message>.+)$'\n",
    "    \n",
    "    data = {\n",
    "        \"timestamp\": [],\n",
    "        \"agent\": [],\n",
    "        \"debug\": [],\n",
    "        \"level\": [],\n",
    "        \"message\": []\n",
    "    }\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        current_log = []\n",
    "        line_count = 0\n",
    "\n",
    "        for line in file:\n",
    "            # Check if the line matches the start of a new log entry\n",
    "            if re.match(pattern, line):\n",
    "                if current_log:\n",
    "                    full_log_entry = \"\\n\".join(current_log)\n",
    "                    match = re.match(pattern, full_log_entry, re.DOTALL)\n",
    "                    if match:\n",
    "                        data[\"timestamp\"].append(match.group('timestamp'))\n",
    "                        data[\"agent\"].append(match.group('agent'))\n",
    "                        data[\"debug\"].append(match.group('debug'))\n",
    "                        data[\"level\"].append(match.group('level'))\n",
    "                        data[\"message\"].append(match.group('message').strip())\n",
    "\n",
    "                current_log = [line.strip()]\n",
    "                line_count = 1\n",
    "            else:\n",
    "                if line_count < 4:\n",
    "                    current_log.append(line.strip())\n",
    "                    line_count += 1\n",
    "\n",
    "        # Append the last log entry\n",
    "        if current_log:\n",
    "            full_log_entry = \"\\n\".join(current_log)\n",
    "            match = re.match(pattern, full_log_entry, re.DOTALL)\n",
    "            if match:\n",
    "                data[\"timestamp\"].append(match.group('timestamp'))\n",
    "                data[\"agent\"].append(match.group('agent'))\n",
    "                data[\"debug\"].append(match.group('debug'))\n",
    "                data[\"level\"].append(match.group('level'))\n",
    "                data[\"message\"].append(match.group('message').strip())\n",
    "\n",
    "    # Create a DataFrame from the collected data\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of Empty DataFrame\n",
      "Columns: [timestamp, agent, debug, level, message]\n",
      "Index: []>\n"
     ]
    }
   ],
   "source": [
    "from haystack.utils import Secret\n",
    "log2=process_log_file('NIRE_540_ASSETS.log')\n",
    "print(log2.head)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_rows=30\n",
    "# Create a list to store the context and prompts\n",
    "data2 = []\n",
    "client2 = OpenAIGenerator(model=\"gpt-3.5-turbo\", generation_kwargs={\"max_tokens\": 4000})\n",
    "# Convert each row to a JSON object suitable for ChatGPT prompts\n",
    "current_context2=f\"\\n\"\n",
    "prompt2=''\n",
    "row_count=0\n",
    "for _, row in log2.iterrows():\n",
    "    context2 = f\"Timestamp: {row['timestamp']}\\nAgent: {row['agent']}\\nDebug: {row['debug']}\\nLevel: {row['level']}\\nMessage: {row['message']}\"\n",
    "    if row_count<=no_of_rows:\n",
    "        current_context2=current_context2+f\"\\n\"+context2\n",
    "        \n",
    "    else:\n",
    "        prompt2 = f\"provide a detaled technical summery of the system for the system log in this given context given bellow . include the time window, how many agents had events. how many error event during the time period and discribe errors:\\n{current_context2}\"\n",
    "        #print(prompt,\"UUUUUUUUUUUUUUUUUUUUUUUUUUUUUU\")\n",
    "        response=client2.run(prompt2)\n",
    "        print(len(data2),len(prompt2),response['replies'])\n",
    "        gptresponse2=response['replies']\n",
    "        data2.append({\"response\": gptresponse2, \"prompt\": prompt2,\"context\":current_context2})\n",
    "        current_context2=f\"\\n\"\n",
    "        time.sleep(10)\n",
    "        row_count=0\n",
    "    row_count=row_count+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    " df2 = pd.DataFrame(data2)\n",
    " df2.to_parquet('540log_mass.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              response  \\\n",
      "0    [The time window for the system log is from 16...   \n",
      "1    [The system log contains events recorded withi...   \n",
      "2    [The system log contains events related to the...   \n",
      "3    [The system log contains multiple entries from...   \n",
      "4    [Time Window: 2024-06-18 16:56:56 to 2024-06-1...   \n",
      "..                                                 ...   \n",
      "661  [The system log contains multiple timestamps w...   \n",
      "662  [Time window: 2024-06-18 17:15:06 to 2024-06-1...   \n",
      "663  [The system log contains events from the platf...   \n",
      "664  [The system log provided captures events from ...   \n",
      "665  [The system log contains multiple events from ...   \n",
      "\n",
      "                                                prompt  \\\n",
      "0    provide a detaled technical summery of the sys...   \n",
      "1    provide a detaled technical summery of the sys...   \n",
      "2    provide a detaled technical summery of the sys...   \n",
      "3    provide a detaled technical summery of the sys...   \n",
      "4    provide a detaled technical summery of the sys...   \n",
      "..                                                 ...   \n",
      "661  provide a detaled technical summery of the sys...   \n",
      "662  provide a detaled technical summery of the sys...   \n",
      "663  provide a detaled technical summery of the sys...   \n",
      "664  provide a detaled technical summery of the sys...   \n",
      "665  provide a detaled technical summery of the sys...   \n",
      "\n",
      "                                               context  \n",
      "0    \\n\\nTimestamp: 2024-06-18 16:56:40,734\\nAgent:...  \n",
      "1    \\n\\nTimestamp: 2024-06-18 16:56:45,089\\nAgent:...  \n",
      "2    \\n\\nTimestamp: 2024-06-18 16:56:49,533\\nAgent:...  \n",
      "3    \\n\\nTimestamp: 2024-06-18 16:56:52,774\\nAgent:...  \n",
      "4    \\n\\nTimestamp: 2024-06-18 16:56:56,091\\nAgent:...  \n",
      "..                                                 ...  \n",
      "661  \\n\\nTimestamp: 2024-06-18 17:15:04,139\\nAgent:...  \n",
      "662  \\n\\nTimestamp: 2024-06-18 17:15:06,077\\nAgent:...  \n",
      "663  \\n\\nTimestamp: 2024-06-18 17:15:08,052\\nAgent:...  \n",
      "664  \\n\\nTimestamp: 2024-06-18 17:15:10,050\\nAgent:...  \n",
      "665  \\n\\nTimestamp: 2024-06-18 17:15:11,686\\nAgent:...  \n",
      "\n",
      "[666 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet('540log_mass.parquet')\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env-ultimate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
